name: UCCL-EP Low Latency Test

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

concurrency:
  group: ep-test
  cancel-in-progress: false

jobs:
  build-on-nodes:
    if: >
      github.event_name == 'push' ||
      (github.event_name == 'pull_request' &&
      !github.event.pull_request.head.repo.fork &&
      github.event.pull_request.draft == false)
    runs-on: ubuntu-latest
    permissions:
      contents: read
    timeout-minutes: 5

    steps:
      - name: Checkout (for artifacts/consistency)
        uses: actions/checkout@v4

      - name: Setup SSH (p4_gate → gh1/gh2)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p ~/.ssh
          echo "${{ secrets.UCCL_DEV_SSH_KEY }}" > ~/.ssh/uccl-dev
          chmod 600 ~/.ssh/uccl-dev

          cat > ~/.ssh/config <<'EOF'
          Host gh1
              User yangzhou_ucberkeley
              HostName localhost
              Port 34455
              ForwardAgent yes
              ProxyCommand ssh -W %h:%p p4_gate
              StrictHostKeyChecking no
              IdentityFile ~/.ssh/uccl-dev

          Host gh2
              User yangzhou_ucberkeley
              HostName localhost
              Port 34456
              ForwardAgent yes
              ProxyCommand ssh -W %h:%p p4_gate
              StrictHostKeyChecking no
              IdentityFile ~/.ssh/uccl-dev

          Host p4_gate
              HostName 98.84.112.172
              User ubuntu
              ForwardAgent yes
              StrictHostKeyChecking no
              IdentityFile ~/.ssh/uccl-dev
          EOF
          chmod 600 ~/.ssh/config

          eval "$(ssh-agent -s)"
          ssh-add ~/.ssh/uccl-dev
          ssh-keyscan -H 98.84.112.172 >> ~/.ssh/known_hosts || true

      - name: Sync repo to gh1 & gh2
        shell: bash
        run: |
          set -euo pipefail
          git submodule update --init --recursive thirdparty/nccl

          sync_to_host() {
            local H="$1"
            echo ">>> Syncing to $H"
            rsync -az --delete \
              -e "ssh -o BatchMode=yes -A" \
              ./ "$H:/home/yangzhou_ucberkeley/uccl-test/"
          }

          sync_to_host gh1 &
          pid1=$!
          sync_to_host gh2 &
          pid2=$!
          wait $pid1
          wait $pid2

      - name: Build & install on gh1 & gh2 (conda env uccl)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p logs

          build_on_host() {
            local H="$1"
            echo ">>> Building on $H"

            ssh -A -o BatchMode=yes "$H" 'bash -lc "
                set -euo pipefail
                source \$HOME/miniconda3/etc/profile.d/conda.sh
                conda activate uccl

                cd /home/yangzhou_ucberkeley/uccl-test/ep
                make clean || true
                set -o pipefail
                make -j install 2>&1 | tee build.log

                if grep -q \"Installation complete. Modules installed as:\" build.log; then
                    echo \"Build completed successfully on '"$H"'\"
                    exit 0
                else
                    echo \"Build marker missing on '"$H"'\"
                    exit 1
                fi
            "'
          }

          build_on_host gh1 &
          pid1=$!
          build_on_host gh2 &
          pid2=$!
          wait $pid1
          wait $pid2

      - name: Run benchmark_remote on gh1 & gh2
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p logs

          check_gpu_free() {
            local H="$1"
            echo ">>> Checking GPU usage on $H"
            ssh -A -o BatchMode=yes "$H" 'bash -lc "
              set -euo pipefail
              if nvidia-smi | grep -q \"No running processes found\"; then
                echo \"GPU is free on $H\"
              else
                echo \"GPU already in use on $H\"
                exit 1
              fi
            "'
          }

          check_gpu_free gh1
          check_gpu_free gh2

          run_test() {
            local H="$1"
            local RANK="$2"
            local MASTER_PORT="$3"
            local SCRIPT="$4"
            local MARKER="$5"
            local LOG="logs/${H}_$(basename $SCRIPT .py).log"

            echo ">>> Launching $SCRIPT on $H (rank=$RANK)"
            ssh -A -o BatchMode=yes "$H" 'bash -lc "
              set -euo pipefail
              source \$HOME/miniconda3/etc/profile.d/conda.sh
              conda activate uccl
              cd /home/yangzhou_ucberkeley/uccl-test/ep

              torchrun \
                --nnodes=2 --nproc_per_node=1 \
                --node_rank='"$RANK"' \
                --master_addr=10.141.1.1 --master_port='"$MASTER_PORT"' \
                bench/'"$SCRIPT"' 2>&1 | tee torchrun.log

              if ! grep -q \"$MARKER\" torchrun.log; then
                echo \"Marker '$MARKER' not found in $SCRIPT on $H\"
                exit 1
              fi
            "' | tee "$LOG"
          }

          trap 'echo "[ERROR] Killing all running jobs"; kill 0' ERR
          run_test gh1 0 12355 benchmark_remote.py "Benchmark elapsed_ms:" &
          pid1=$!
          sleep 1
          run_test gh2 1 12355 benchmark_remote.py "Test completed." &
          pid2=$!
          wait -n || { echo "[ERROR] benchmark_remote failed"; kill 0; exit 1; }
          wait
          echo "Benchmark remote test passed on both hosts"

      - name: Run internode simple test on gh1 & gh2
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p logs

          check_gpu_free() {
            local H="$1"
            echo ">>> Checking GPU usage on $H"
            ssh -A -o BatchMode=yes "$H" 'bash -lc "
              set -euo pipefail
              if nvidia-smi | grep -q \"No running processes found\"; then
                echo \"GPU is free on $H\"
              else
                echo \"GPU already in use on $H\"
                exit 1
              fi
            "'
          }

          check_gpu_free gh1
          check_gpu_free gh2

          run_test() {
            local H="$1"
            local RANK="$2"
            local MASTER_PORT="$3"
            local SCRIPT="$4"
            local MARKER="$5"
            local LOG="logs/${H}_$(basename $SCRIPT .py).log"

            echo ">>> Launching $SCRIPT on $H (rank=$RANK)"
            ssh -A -o BatchMode=yes "$H" 'bash -lc "
              set -euo pipefail
              source \$HOME/miniconda3/etc/profile.d/conda.sh
              conda activate uccl
              cd /home/yangzhou_ucberkeley/uccl-test/ep

              torchrun \
                --nnodes=2 --nproc_per_node=1 \
                --node_rank='"$RANK"' \
                --master_addr=10.141.1.1 --master_port='"$MASTER_PORT"' \
                bench/'"$SCRIPT"' 2>&1 | tee torchrun.log

              if ! grep -q \"$MARKER\" torchrun.log; then
                echo \"Marker '$MARKER' not found in $SCRIPT on $H\"
                exit 1
              fi
            "' | tee "$LOG"
          }

          trap 'echo "[ERROR] Killing all running jobs"; kill 0' ERR
          run_test gh2 1 12356 test_internode_simple.py "[simple-test] ✓ All tests passed!" &
          pid2=$!
          sleep 1
          run_test gh1 0 12356 test_internode_simple.py "[simple-test] ✓ All tests passed!" &
          pid1=$!
          wait -n || { echo "[ERROR] internode simple test failed"; kill 0; exit 1; }
          wait
          echo "Internode simple test passed on both hosts"

      - name: Run low-latency test on gh1 & gh2
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p logs

          check_gpu_free() {
            local H="$1"
            echo ">>> Checking GPU usage on $H"
            ssh -A -o BatchMode=yes "$H" 'bash -lc "
              set -euo pipefail
              source \$HOME/miniconda3/etc/profile.d/conda.sh
              conda activate uccl

              if nvidia-smi | grep -q \"No running processes found\"; then
                echo \"GPU is free on $H\"
              else
                echo \"GPU already in use on $H\"
                exit 1
              fi
            "'
          }

          check_gpu_free gh1
          check_gpu_free gh2

          run_ll() {
            local H="$1"
            local RANK="$2"
            echo ">>> Launching torchrun on $H (rank=$RANK)"
            ssh -A -o BatchMode=yes "$H" 'bash -lc "
              set -euo pipefail
              source \$HOME/miniconda3/etc/profile.d/conda.sh
              conda activate uccl

              cd /home/yangzhou_ucberkeley/uccl-test/ep
              torchrun \
                --nnodes=2 --nproc_per_node=1 \
                --node_rank='"$RANK"' \
                --master_addr=10.141.1.1 --master_port=12357 \
                bench/test_low_latency.py \
                --num-tokens=128 --hidden=7168 --num-topk=1 --num-experts=24 2>&1 | tee torchrun.log

              if ! grep -q \"✓ All correctness tests passed!\" torchrun.log; then
                echo \"Correctness tests did not pass on $H\"
                exit 1
              fi
            "' | tee "logs/${H}_torchrun.log"
          }

          trap 'echo "[ERROR] Killing all running jobs"; kill 0' ERR
          run_ll gh2 1 &
          pid2=$!
          sleep 1
          run_ll gh1 0 &
          pid1=$!
          wait -n || { echo "[ERROR] low-latency test failed"; kill 0; exit 1; }
          wait
          echo "Low-latency test passed on both hosts"

      - name: Fetch remote logs (build + torchrun)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p logs
          scp -o BatchMode=yes -A gh1:/home/yangzhou_ucberkeley/uccl-test/ep/build.log logs/gh1_build.log || true
          scp -o BatchMode=yes -A gh2:/home/yangzhou_ucberkeley/uccl-test/ep/build.log logs/gh2_build.log || true
          scp -o BatchMode=yes -A gh1:/home/yangzhou_ucberkeley/uccl-test/ep/torchrun.log logs/gh1_torchrun.log || true
          scp -o BatchMode=yes -A gh2:/home/yangzhou_ucberkeley/uccl-test/ep/torchrun.log logs/gh2_torchrun.log || true

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: dual-node-build-and-ll-logs
          path: logs/